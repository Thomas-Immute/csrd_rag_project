import os
import pinecone
import openai

# Initiera Pinecone
pc = pinecone.Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index = pc.Index("csrd-index")

# Testfr√•ga
query_text = "Vad inneb√§r CSRD f√∂r sm√• f√∂retag?"

# Skapa embedding f√∂r fr√•gan
openai.api_key = os.getenv("OPENAI_API_KEY")
response = openai.embeddings.create(
    input=query_text,
    model="text-embedding-ada-002"
)
query_embedding = response.data[0].embedding

# S√∂ka i Pinecone
search_results = index.query(
    vector=query_embedding,
    top_k=3,  # H√§mta relevanta tr√§ffar
    include_metadata=True
)

# Samla ihop och organisera tr√§ffar
organized_results = []
for match in search_results["matches"]:
    chunk_id = match["metadata"].get("chunk_id", None)
    doc_name = match["metadata"].get("document_name", "Ok√§nt dokument")
    section = match["metadata"].get("section", "Ok√§nt avsnitt")
    page = match["metadata"].get("page", "N/A")
    timestamp = match["metadata"].get("timestamp", "N/A")
    text = match["metadata"].get("text", "")

    # H√§mta angr√§nsande chunks
    adjacent_chunks = []
    if chunk_id is not None:
        # H√§mta f√∂reg√•ende chunk
        prev_chunk = index.query(
            vector=query_embedding,
            filter={"chunk_id": chunk_id - 1, "document_name": doc_name},
            top_k=1,
            include_metadata=True
        )
        # H√§mta n√§sta chunk
        next_chunk = index.query(
            vector=query_embedding,
            filter={"chunk_id": chunk_id + 1, "document_name": doc_name},
            top_k=1,
            include_metadata=True
        )

        if prev_chunk["matches"]:
            adjacent_chunks.append(prev_chunk["matches"][0]["metadata"]["text"])
        if next_chunk["matches"]:
            adjacent_chunks.append(next_chunk["matches"][0]["metadata"]["text"])

    # Kombinera angr√§nsande chunks
    full_text = "\n".join([t for t in [*adjacent_chunks, text] if t])

    # Organisera resultat
    organized_results.append(
        f"""
üìÑ **Dokument:** {doc_name}
üìå **Avsnitt:** {section}
üìú **Sida:** {page}
‚è≥ **Tidsst√§mpel:** {timestamp}

‚úçÔ∏è **Textutdrag:**  
{full_text}
---
""")

# Sl√• ihop resultaten
final_text = "\n\n".join(organized_results)

# Anv√§nd GPT f√∂r att skapa ett sammanh√§ngande svar
summary_response = openai.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "Sammanfatta och f√∂rklara svaret tydligt."},
        {"role": "user", "content": f"Fr√•ga: {query_text}\n\nRelevanta utdrag:\n{final_text}"}
    ]
)

# Visa f√∂rb√§ttrat svar
print("\nüîç **Sammanfattat svar:**")
print(summary_response.choices[0].message.content)
